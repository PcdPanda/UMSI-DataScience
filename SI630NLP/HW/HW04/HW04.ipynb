{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "639e8eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 955 ms, sys: 168 ms, total: 1.12 s\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import seaborn as sns\n",
    "from typing import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments, PreTrainedTokenizerFast, BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "import pet\n",
    "from pet.pvp import PVP, PVPS\n",
    "from pet.utils import InputExample\n",
    "from pet.tasks import DataProcessor, PROCESSORS, TASK_HELPERS \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f622fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../../MiniLM\"\n",
    "df_train = pd.read_csv(\"hw4_train.csv\", index_col=\"id\")\n",
    "df_test = pd.read_csv(\"hw4_test.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a808126c",
   "metadata": {},
   "source": [
    "## 1: Tokenize single word into token ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad70e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 36\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "def tokenize(word: str):\n",
    "    return tokenizer(word, add_special_tokens=False, padding=False)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6edf04d",
   "metadata": {},
   "source": [
    "## 2. 10 different prompts for classification and at least 2 verbalizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25badf0",
   "metadata": {},
   "source": [
    "1. In summary, [Review text] sounds [Mask]!\n",
    "2. If someone say [Review text] to me, he must be a [Mask] guy.\n",
    "3. How can anyone say [Review text]? He must be so [Mask]!\n",
    "4. Saying something like [Review text] can make the conversation [Mask].\n",
    "5. Only [Mask] people will say [Review text] to each other!\n",
    "6. It sounds [Mask] to say [Review text]\n",
    "7. I say [Review text] when it is [Mask].\n",
    "8. [Review text]: [Mask].\n",
    "9. I feel [Mask] when hearing people say [Review text].\n",
    "10. How does [Review text] sounds like? It is [Mask]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a8fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTaskPVP(PVP):\n",
    "    TASK_NAME = \"SI630-HW4\"\n",
    "    VERBALIZER = {\"0\": [\"boring\",\"ordinary\"], \"1\": [\"toxic\", \"awful\"]}\n",
    "    def get_parts(self, example: InputExample):\n",
    "        \"\"\"\n",
    "        This function defines the actual patterns: It takes as input an example and outputs the result of applying a\n",
    "        pattern to it. To allow for multiple patterns, a pattern_id can be passed to the PVP's constructor. This\n",
    "        method must implement the application of all patterns.\n",
    "        \"\"\"\n",
    "        text = self.shortenable(example.text_a)\n",
    "        patterns = {\n",
    "            0: [\"In summary, \", text, \" sounds \", self.mask, \"!\"],\n",
    "            1: [\"If someone says \", text, \" to me, he must be a \", self.mask, \" guy.\"],\n",
    "            2: [\"How can anyone say \", text, \"? He must be so \", self.mask, \"!\"],\n",
    "            3: [\"Saying something like \", text, \"can make the conversation \", self.mask, \".\"],\n",
    "            4: [\"Only \", self.mask, \" people will say \", text, \" to each other!\"],\n",
    "            5: [\"It sounds \", self.mask, \" to say \", text, \".\"],\n",
    "            6: [\"I say \", text, \" when it is \", self.mask, \".\"],\n",
    "            7: [text, \": \", self.mask, \".\"],\n",
    "            8: [\"I feel \", self.mask, \" when hearing people say \", text, \".\"],\n",
    "            9: [\"How does \", text, \" sounds like? It is \", self.mask, \".\"]\n",
    "        }\n",
    "        if self.pattern_id in patterns.keys():\n",
    "            return patterns[self.pattern_id]\n",
    "        else:\n",
    "            raise ValueError(\"No pattern implemented for id {}\".format(self.pattern_id))\n",
    "\n",
    "    def verbalize(self, label) -> List[str]:\n",
    "        return MyTaskPVP.VERBALIZER[label]\n",
    "\n",
    "\n",
    "# register the PVP for this task with its name\n",
    "PVPS[MyTaskPVP.TASK_NAME] = MyTaskPVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1509a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTaskDataProcessor(DataProcessor):\n",
    "    \"\"\"\n",
    "    Example for a data processor.\n",
    "    \"\"\"\n",
    "    TASK_NAME = \"SI630-HW4\"\n",
    "    TRAIN_FILE_NAME = \"hw4_train.csv\"\n",
    "    TEST_FILE_NAME = \"hw4_test.csv\"\n",
    "\n",
    "    LABELS = [\"0\", \"1\"]\n",
    "\n",
    "    def get_train_examples(self, data_dir: str=\".\", size: int=-1) -> List[InputExample]:\n",
    "        return self._create_examples(os.path.join(data_dir, MyTaskDataProcessor.TRAIN_FILE_NAME), \"train\", size=size)\n",
    "\n",
    "    def get_test_examples(self, data_dir: str=\".\", size: int=-1) -> List[InputExample]:\n",
    "        return self._create_examples(os.path.join(data_dir, MyTaskDataProcessor.TEST_FILE_NAME), \"test\", size=size)\n",
    "\n",
    "    def get_dev_examples(self, data_dir: str=\".\") -> List[InputExample]:\n",
    "        return self._create_examples(os.path.join(data_dir, MyTaskDataProcessor.DEV_FILE_NAME), \"dev\")\n",
    "\n",
    "    def get_unlabeled_examples(self, data_dir: str=\".\") -> List[InputExample]:\n",
    "        return self._create_examples(os.path.join(data_dir, MyTaskDataProcessor.UNLABELED_FILE_NAME), \"unlabeled\")\n",
    "    \n",
    "    def get_labels(self) -> List[str]:\n",
    "        \"\"\"This method returns all possible labels for the task.\"\"\"\n",
    "        return MyTaskDataProcessor.LABELS\n",
    "    \n",
    "    def _create_examples(self, path, set_type, max_examples=-1, skip_first=0, size: int=-1):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        examples = []\n",
    "        df = pd.read_csv(path)\n",
    "        if size != -1:\n",
    "            ratio = size / len(df)\n",
    "            df_toxic = df[df.toxic==1]\n",
    "            df_nontoxic = df[df.toxic==0]\n",
    "            df = pd.concat([df_toxic.sample(int(ratio * len(df_toxic))), df_nontoxic.sample(int(ratio * len(df_nontoxic)))])\n",
    "        for idx, row in df.iterrows():\n",
    "            guid = \"%s-%s\" % (set_type, idx)\n",
    "            example = InputExample(guid=guid, text_a=row.comment_text, text_b=None, label=str(row.toxic))\n",
    "            examples.append(example)     \n",
    "        return examples\n",
    "PROCESSORS[MyTaskDataProcessor.TASK_NAME] = MyTaskDataProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8278a539",
   "metadata": {},
   "source": [
    "## 3. Train MiniLM at least for 2 epochs and validate by F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c5fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_tokenized = tokenizer(list(df_train.comment_text), padding=True, truncation=True, max_length=256)\n",
    "train_dataset = Dataset(train_tokenized, list(df_train.toxic))\n",
    "test_tokenized = tokenizer(list(df_test.comment_text), padding=True, truncation=True, max_length=256)\n",
    "test_dataset = Dataset(test_tokenized, list(df_test.toxic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b0ced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):    \n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(y_true=labels, y_pred=preds)\n",
    "    recall = recall_score(y_true=labels, y_pred=preds, average='micro')\n",
    "    precision = precision_score(y_true=labels, y_pred=preds, average='micro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=preds, average='micro')\n",
    "    return {\"acc\":acc, \"recall\":recall, \"precision\": precision, \"f1\": f1}\n",
    "\n",
    "def train(model, train_dataset):\n",
    "    model.to(device)\n",
    "    args = TrainingArguments(\n",
    "        output_dir=\"output\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=500,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=2,\n",
    "        seed=123,\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    trainer.train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd4e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "train_model_path = \"MiniModelRegression\"\n",
    "trained_model = train(model, train_dataset)\n",
    "# trained_model = BertForSequenceClassification.from_pretrained(train_model_path, num_labels=1)\n",
    "trained_predictor = Trainer(model=trained_model)\n",
    "trained_predictor.save_model(train_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011232d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prediction = trained_predictor.predict(test_dataset).predictions\n",
    "pred_label = np.argmax(prediction, axis=1).flatten()\n",
    "acc = accuracy_score(pred_label, df_test.toxic)\n",
    "f1 = f1_score(pred_label, df_test.toxic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69952a32",
   "metadata": {},
   "source": [
    "For MiniLM bert model, Acc is $0.92$, F1 is $0.67$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcdb02d",
   "metadata": {},
   "source": [
    "## 4. Use pattern and verbalizer to train PET on 10, 50, 100, 500 random instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce55b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for size in [10, 50, 100, 500]:\n",
    "    model_config = pet.WrapperConfig(\"bert\", model_path, \"sequence_classifier\", \"SI630-HW4\", 256, [\"0\", \"1\"], list(range(10)))\n",
    "    train_config = pet.TrainConfig(str(device), batch_size, batch_size)\n",
    "    eval_config = pet.EvalConfig(str(device), per_gpu_eval_batch_size=batch_size, metrics=[\"acc\", \"f1\"])\n",
    "    output_dir = \"output{}\".format(size)\n",
    "    train_data = MyTaskDataProcessor().get_train_examples(\".\", size=size)\n",
    "    test_data = MyTaskDataProcessor().get_test_examples(\".\", size=size)\n",
    "    pattern_ids = list(range(10))\n",
    "    pet.train_pet_ensemble(model_config, train_config, eval_config, pattern_ids, output_dir,train_data=train_data, eval_data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbd008e",
   "metadata": {},
   "source": [
    "For PET10, acc is $0.46\\pm0.37$, F1 is $0.18\\pm0.12$\n",
    "\n",
    "For PET50, acc is $0.53\\pm0.37$, F1 is $0.26\\pm0.14$\n",
    "\n",
    "For PET100, acc is $0.55\\pm0.21$, F1 is $0.29\\pm0.06$\n",
    "\n",
    "For PET500, acc is $0.84\\pm0.02$, F1 is $0.52\\pm0.02$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6874558f",
   "metadata": {},
   "source": [
    "## 5. Use Seaborn to plot F1 for PET and MiniLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ffb9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    \"Model\":[\"PET10\", \"PET50\", \"PET100\", \"PET500\", \"MiniLM\"],\n",
    "    \"Acc\":[0.46, 0.53, 0.55, 0.84, 0.92],\n",
    "    \"F1\": [0.18, 0.26, 0.29, 0.52, 0.67]\n",
    "    }\n",
    ").melt(id_vars=[\"Model\"], value_vars=[\"Acc\", \"F1\"], var_name=\"ScoreType\", value_name=\"Value\").sort_values([\"Model\", \"ScoreType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97928a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fbd6b9a7430>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(data=data, x=\"Model\", col=\"ScoreType\", y=\"Value\", kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5678ead1",
   "metadata": {},
   "source": [
    "With more instance used for PET model's training, the score for PET 500 increase greatly. The score for PET 500 is quite close to the MiniLM model. Therefore, I think 1000 samples should be enough for PET model to reach MiniLM model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
